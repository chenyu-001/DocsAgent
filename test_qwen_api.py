#!/usr/bin/env python3
"""æµ‹è¯•é€šä¹‰åƒé—® API è¿æ¥å’Œæ¨¡å‹è®¿é—®æƒé™"""

import os
from openai import OpenAI

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
API_KEY = os.getenv("LLM_API_KEY", "your-api-key-here")
API_BASE = os.getenv("LLM_API_BASE", "https://dashscope.aliyuncs.com/compatible-mode/v1")

# è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
MODELS_TO_TEST = [
    "qwen-turbo",
    "qwen-plus",
    "qwen-max",
    "qwen-long",
]

def test_model(client, model_name):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹æ˜¯å¦å¯è®¿é—®"""
    try:
        print(f"\næµ‹è¯•æ¨¡å‹: {model_name}")
        print("-" * 50)

        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ],
            max_tokens=100,
            temperature=0.7,
        )

        answer = response.choices[0].message.content
        print(f"âœ… æˆåŠŸ! æ¨¡å‹ '{model_name}' å¯ä»¥è®¿é—®")
        print(f"å›ç­”: {answer[:100]}...")
        return True

    except Exception as e:
        error_msg = str(e)
        print(f"âŒ å¤±è´¥! æ¨¡å‹ '{model_name}' æ— æ³•è®¿é—®")
        print(f"é”™è¯¯: {error_msg}")

        # è§£æå¸¸è§é”™è¯¯
        if "403" in error_msg or "AccessDenied" in error_msg:
            print("ğŸ’¡ æç¤º: è¯¥æ¨¡å‹æœªå¼€é€šæˆ–æ— è®¿é—®æƒé™")
        elif "401" in error_msg or "Invalid" in error_msg:
            print("ğŸ’¡ æç¤º: API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
        elif "400" in error_msg:
            print("ğŸ’¡ æç¤º: è¯·æ±‚å‚æ•°é”™è¯¯")

        return False

def main():
    print("=" * 50)
    print("é€šä¹‰åƒé—® API æµ‹è¯•å·¥å…·")
    print("=" * 50)

    # æ£€æŸ¥ API Key
    if API_KEY == "your-api-key-here" or not API_KEY:
        print("\nâŒ é”™è¯¯: æœªé…ç½® LLM_API_KEY")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ API Key")
        return

    print(f"\nAPI Base: {API_BASE}")
    print(f"API Key: {API_KEY[:20]}...")

    # åˆ›å»ºå®¢æˆ·ç«¯
    client = OpenAI(
        api_key=API_KEY,
        base_url=API_BASE,
    )

    # æµ‹è¯•æ‰€æœ‰æ¨¡å‹
    results = {}
    for model in MODELS_TO_TEST:
        results[model] = test_model(client, model)

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)

    available_models = [m for m, success in results.items() if success]
    unavailable_models = [m for m, success in results.items() if not success]

    if available_models:
        print(f"\nâœ… å¯ç”¨æ¨¡å‹ ({len(available_models)}ä¸ª):")
        for model in available_models:
            print(f"  - {model}")

    if unavailable_models:
        print(f"\nâŒ ä¸å¯ç”¨æ¨¡å‹ ({len(unavailable_models)}ä¸ª):")
        for model in unavailable_models:
            print(f"  - {model}")

    # ç»™å‡ºå»ºè®®
    print("\n" + "=" * 50)
    print("å»ºè®®")
    print("=" * 50)

    if available_models:
        recommended = available_models[0]
        print(f"\næ¨èä½¿ç”¨: {recommended}")
        print(f"\nåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®:")
        print(f"LLM_MODEL_NAME={recommended}")
    else:
        print("\nâš ï¸  æ‰€æœ‰æ¨¡å‹éƒ½æ— æ³•è®¿é—®!")
        print("\nè¯·æ£€æŸ¥:")
        print("1. API Key æ˜¯å¦æ­£ç¡®é…ç½®")
        print("2. æ˜¯å¦åœ¨é˜¿é‡Œäº‘æ§åˆ¶å°å¼€é€šäº†ç›¸åº”çš„æ¨¡å‹æœåŠ¡")
        print("3. è´¦æˆ·æ˜¯å¦æœ‰è¶³å¤Ÿçš„ä½™é¢æˆ–é¢åº¦")
        print("\nè®¿é—®æ§åˆ¶å°: https://dashscope.console.aliyun.com/")

if __name__ == "__main__":
    main()
